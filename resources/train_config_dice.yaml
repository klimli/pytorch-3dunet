# use a fixed random seed to guarantee that when you run the code twice you will get the same outcome
manual_seed: 0
# model configuration
model:
  # model class
  name: UNet3D
  # number of input channels to the model
  in_channels: 1
  # number of output channels
  out_channels: 1
  # determines the order of operators in a single layer (crg - Conv3d+ReLU+GroupNorm)
  layer_order: crg
  # feature maps scale factor
  f_maps: 32
  # number of groups in the groupnorm
  num_groups: 8
  # apply element-wise nn.Sigmoid after the final 1x1 convolution, otherwise apply nn.Softmax
  final_sigmoid: true
# trainer configuration
trainer:
  # path to the checkpoint directory
  checkpoint_dir: 3dunet
  # path to latest checkpoint; if provided the training will be resumed from that checkpoint
  resume: null
  # how many iterations between validations
  validate_after_iters: 20
  # how many iterations between tensorboard logging
  log_after_iters: 20
  # max number of epochs
  epochs: 1
  # max number of iterations
  iters: 100000
  # model with higher eval score is considered better
  eval_score_higher_is_better: True
# optimizer configuration
optimizer:
  # initial learning rate
  learning_rate: 0.0002
  # weight decay
  weight_decay: 0.0001
# loss function configuration
loss:
  # loss function to be used during training
  name: DiceLoss
  # A manual rescaling weight given to each class.
  loss_weight: null
  # a target value that is ignored and does not contribute to the input gradient
  ignore_index: null
# evaluation metric configuration
eval_metric:
  name: MeanIoU
  # a target label that is ignored during metric evaluation
  ignore_index: null
lr_scheduler:
  name: MultiStepLR
  milestones: [10, 30, 60]
  gamma: 0.2
# data loaders configuration
loaders:
  # train patch size given to the network (adapt to fit in your GPU mem, generally the bigger patch the better)
  train_patch: [32, 64, 64]
  # train stride between patches
  train_stride: [8, 16, 16]
  # validation patch (can be bigger than train patch since there is no backprop)
  val_patch: [32, 64, 64]
  # validation stride (validation patches doesn't need to overlap)
  val_stride: [32, 64, 64]
  # path to the raw data within the H5
  raw_internal_path: raw
  # path to the the label data withtin the H5
  label_internal_path: label
  # paths to the training datasets
  train_path:
    - 'resources/P99B99.h5'
    - 'resources/P147B147.h5'
    - 'resources/P140B140.h5'
    - 'resources/P55B55.h5'
    - 'resources/P105B105.h5'
    - 'resources/P146B146.h5'
    - 'resources/P133B133.h5'
    - 'resources/P111B111.h5'
    - 'resources/P44B44.h5'
    - 'resources/P4B4.h5'
    - 'resources/P118B118.h5'
    - 'resources/P39B39.h5'
    - 'resources/P134B134.h5'
    - 'resources/P83B83.h5'
    - 'resources/P21B21.h5'
    - 'resources/P56B56.h5'
    - 'resources/P106B106.h5'
    - 'resources/P122B122.h5'
    - 'resources/P78B78.h5'
    - 'resources/P72B72.h5'
    - 'resources/P47B47.h5'
    - 'resources/P13B13.h5'
    - 'resources/P67B67.h5'
    - 'resources/P153B153.h5'
    - 'resources/P60B60.h5'
    - 'resources/P19B19.h5'
    - 'resources/P10B10.h5'
    - 'resources/P144B144.h5'
    - 'resources/P150B150.h5'
    - 'resources/P54B54.h5'
    - 'resources/P137B137.h5'
    - 'resources/P109B109.h5'
    - 'resources/P102B102.h5'
    - 'resources/P129B129.h5'
    - 'resources/P86B86.h5'
    - 'resources/P107B107.h5'
    - 'resources/P17B17.h5'
    - 'resources/P145B145.h5'
    - 'resources/P100B100.h5'
    - 'resources/P23B23.h5'
    - 'resources/P45B45.h5'
    - 'resources/P138B138.h5'
    - 'resources/P66B66.h5'
    - 'resources/P22B22.h5'
    - 'resources/P74B74.h5'
    - 'resources/P90B90.h5'
    - 'resources/P11B11.h5'
    - 'resources/P2B2.h5'
    - 'resources/P12B12.h5'
    - 'resources/P48B48.h5'
    - 'resources/P27B27.h5'
    - 'resources/P123B123.h5'
    - 'resources/P94B94.h5'
    - 'resources/P35B35.h5'
    - 'resources/P69B69.h5'
    - 'resources/P131B131.h5'
    - 'resources/P121B121.h5'
    - 'resources/P112B112.h5'
    - 'resources/P33B33.h5'
    - 'resources/P75B75.h5'
    - 'resources/P135B135.h5'
    - 'resources/P104B104.h5'
    - 'resources/P108B108.h5'
    - 'resources/P62B62.h5'
    - 'resources/P120B120.h5'
    - 'resources/P41B41.h5'
    - 'resources/P97B97.h5'
    - 'resources/P31B31.h5'
    - 'resources/P15B15.h5'
    - 'resources/P58B58.h5'
    - 'resources/P85B85.h5'
    - 'resources/P53B53.h5'
    - 'resources/P16B16.h5'
    - 'resources/P73B73.h5'
    - 'resources/P125B125.h5'
    - 'resources/P14B14.h5'
    - 'resources/P76B76.h5'
    - 'resources/P26B26.h5'
    - 'resources/P126B126.h5'
    - 'resources/P36B36.h5'
    - 'resources/P68B68.h5'
    - 'resources/P42B42.h5'
    - 'resources/P130B130.h5'
    - 'resources/P9B9.h5'
    - 'resources/P119B119.h5'
    - 'resources/P101B101.h5'
    - 'resources/P132B132.h5'
    - 'resources/P49B49.h5'
    - 'resources/P34B34.h5'
    - 'resources/P81B81.h5'
    - 'resources/P88B88.h5'
    - 'resources/P28B28.h5'
    - 'resources/P40B40.h5'
    - 'resources/P148B148.h5'
    - 'resources/P57B57.h5'
    - 'resources/P46B46.h5'
    - 'resources/P99B99.h5'
    - 'resources/P96B96.h5'
    - 'resources/P8B8.h5'
    - 'resources/P117B117.h5'
    - 'resources/P92B92.h5'
    - 'resources/P98B98.h5'
    - 'resources/P25B25.h5'
    - 'resources/P29B29.h5'
    - 'resources/P20B20.h5'
    - 'resources/P64B64.h5'
    - 'resources/P63B63.h5'
    - 'resources/P5B5.h5'
    - 'resources/P149B149.h5'
    - 'resources/P52B52.h5'
    - 'resources/P24B24.h5'
    - 'resources/P7B7.h5'
    - 'resources/P95B95.h5'
    - 'resources/P110B110.h5'
    - 'resources/P143B143.h5'
    - 'resources/P32B32.h5'
    - 'resources/P152B152.h5'
    - 'resources/P113B113.h5'
    - 'resources/P115B115.h5'
    - 'resources/P70B70.h5'
    - 'resources/P61B61.h5'
    - 'resources/P128B128.h5'
    - 'resources/P50B50.h5'
    - 'resources/P18B18.h5'


  # paths to the validation datasets
  val_path:
    - 'resources/P114B114.h5'
    - 'resources/P82B82.h5'
    - 'resources/P124B124.h5'
    - 'resources/P141B141.h5'
    - 'resources/P84B84.h5'
    - 'resources/P37B37.h5'
    - 'resources/P38B38.h5'
    - 'resources/P51B51.h5'
    - 'resources/P3B3.h5'
    - 'resources/P79B79.h5'

  # how many subprocesses to use for data loading
  num_workers: 8
  # data transformations/augmentations
  transformer:
    train:
      raw:
        - name: Normalize
        # - name: RandomFlip
        # - name: RandomRotate90
        # - name: RandomRotate
        #   # rotate only in ZY only
        #   axes: [[2, 1]]
        #   angle_spectrum: 15
        #   mode: reflect
        # - name: ElasticDeformation
        #   spline_order: 3
        # - name: RandomContrast
        - name: ToTensor
          expand_dims: true
      label:
        # - name: RandomFlip
        # - name: RandomRotate90
        # - name: RandomRotate
          # rotate only in ZY only
        #   axes: [[2, 1]]
        #   angle_spectrum: 15
        #   mode: reflect
        # - name: ElasticDeformation
        #   spline_order: 0
        - name: ToTensor
          expand_dims: true
          dtype: 'long'
    test:
      raw:
        - name: Normalize
        - name: ToTensor
          expand_dims: true
      label:
        - name: ToTensor
          expand_dims: true
          dtype: 'long'
